# JAI ì¸ê³µì§€ëŠ¥ ë§Œë“¤ê¸°: ë‹¨ê³„ë³„ ê°€ì´ë“œ

ë³¸ ë¬¸ì„œë¥¼ ë”°ë¼í•˜ë©´ ìì‹ ë§Œì˜ Job LLMì„ ì²˜ìŒë¶€í„° ì§ì ‘ êµ¬í˜„í•˜ê³  í•™ìŠµì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

---

## ê°œìš”

**JAI(Job AI)**ëŠ” ì „ ì„¸ê³„ êµ¬ì¸/êµ¬ì§ ì •ë³´ ìƒì„±ì— íŠ¹í™”ëœ LLMì„ ë§Œë“œëŠ” í•™ìŠµ í”„ë¡œì íŠ¸ì…ë‹ˆë‹¤.

### í™œìš© ì˜ˆì‹œ

> í•´ì™¸ ì·¨ì—…ì„ ì¤€ë¹„ ì¤‘ â†’ ë¯¸êµ­ ì‹¤ë¦¬ì½˜ë°¸ë¦¬ ì†Œí”„íŠ¸ì›¨ì–´ ì—”ì§€ë‹ˆì–´ ì±„ìš© ì •ë³´ê°€ í•„ìš”í•¨ â†’ JAIì—ê²Œ ì§ˆë¬¸

ì´ëŸ° ìƒí™©ì—ì„œ ì „ ì„¸ê³„ì— í©ì–´ì ¸ ìˆëŠ” êµ¬ì¸/êµ¬ì§ ì •ë³´ë¥¼ ì œê³µí•˜ëŠ” LLMì…ë‹ˆë‹¤.

---

## 1ë‹¨ê³„: í”„ë¡œì íŠ¸ ìƒì„±

```bash
mkdir jai
cd jai
uv init
```

`uv init` ëª…ë ¹ì–´ê°€ `pyproject.toml` íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤.

> ğŸ“š **ì°¸ê³ **: [02-project-structure.md](docs/02-project-structure.md) - í”„ë¡œì íŠ¸ êµ¬ì¡°

---

## 2ë‹¨ê³„: íŒ¨í‚¤ì§€ ì„¤ì¹˜

```bash
uv add torch tokenizers tqdm numpy
```

| íŒ¨í‚¤ì§€ | ìš©ë„ |
|--------|------|
| `torch` | PyTorch ë”¥ëŸ¬ë‹ í”„ë ˆì„ì›Œí¬ |
| `tokenizers` | BPE í† í¬ë‚˜ì´ì € |
| `tqdm` | ì§„í–‰ë¥  í‘œì‹œ |
| `numpy` | ìˆ˜ì¹˜ ì—°ì‚° |

> ğŸ“š **ì°¸ê³ **: [01-environment-setup.md](docs/01-environment-setup.md) - í™˜ê²½ ì„¤ì •

---

## 3ë‹¨ê³„: MPS í™•ì¸

Apple Silicon Macì—ì„œ GPU ê°€ì† ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.

```bash
uv run python -c "import torch; print('MPS ì‚¬ìš© ê°€ëŠ¥:', torch.backends.mps.is_available())"
```

`True`ê°€ ì¶œë ¥ë˜ë©´ GPU ê°€ì†ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

> ğŸ“š **ì°¸ê³ **: [01-environment-setup.md](docs/01-environment-setup.md) - í™˜ê²½ ì„¤ì •

---

## 4ë‹¨ê³„: í´ë” êµ¬ì¡° ìƒì„±

LLM í•™ìŠµì— í•„ìš”í•œ í´ë”ë“¤ì„ ìƒì„±í•©ë‹ˆë‹¤.

```bash
mkdir -p data scripts checkpoints
```

```
jai/
â”œâ”€â”€ data/           # ë°ì´í„° íŒŒì¼
â”œâ”€â”€ scripts/        # Python ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ checkpoints/    # ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸
â””â”€â”€ pyproject.toml  # í”„ë¡œì íŠ¸ ì„¤ì •
```

### ê° í´ë” ì—­í• 

| í´ë” | ìš©ë„ | ìƒì„±ë˜ëŠ” íŒŒì¼ |
|------|------|---------------|
| `data/` | í•™ìŠµ ë°ì´í„° ì €ì¥ | `raw.txt`, `samples.txt`, `tokenizer.json`, `train.bin`, `val.bin` |
| `scripts/` | ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸ | `prepare_samples.py`, `train_tokenizer.py`, `build_bin_dataset.py`, `train_gpt.py`, `generate.py` |
| `checkpoints/` | í•™ìŠµëœ ëª¨ë¸ ì €ì¥ | `ckpt.pt` (ëª¨ë¸ ê°€ì¤‘ì¹˜, ì˜µí‹°ë§ˆì´ì € ìƒíƒœ) |

### ê°œë… ì„¤ëª…

- [ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ (`ckpt.pt`)](study.md#ì²´í¬í¬ì¸íŠ¸-íŒŒì¼-ckptpt) - ëª¨ë¸ ê°€ì¤‘ì¹˜, ì˜µí‹°ë§ˆì´ì € ìƒíƒœ, í•™ìŠµ ë‹¨ê³„
- [ëª¨ë¸ ê°€ì¤‘ì¹˜ vs ë²¡í„°](study.md#ëª¨ë¸-ê°€ì¤‘ì¹˜-vs-ë²¡í„°) - ì—­í• ê³¼ í˜•íƒœì˜ ì°¨ì´
- [íŒŒë¼ë¯¸í„°ë€?](study.md#íŒŒë¼ë¯¸í„°-parameter) - ëª¨ë¸ì´ í•™ìŠµí•˜ëŠ” ì¡°ì ˆ ê°€ëŠ¥í•œ ìˆ«ì

> ğŸ“š **ì°¸ê³ **: [02-project-structure.md](docs/02-project-structure.md) - í”„ë¡œì íŠ¸ êµ¬ì¡°

---

## 5ë‹¨ê³„: ë°ì´í„° ì¤€ë¹„

`data/raw.txt`ì— ì›ë³¸ êµ¬ì¸/êµ¬ì§ ë°ì´í„°ë¥¼ ì¤€ë¹„í•©ë‹ˆë‹¤.

```bash
uv run python scripts/prepare_samples.py
```

**ê²°ê³¼**: `data/samples.txt` ìƒì„±

> ğŸ“š **ì°¸ê³ **: [03-data-preparation.md](docs/03-data-preparation.md) - ë°ì´í„° ì „ì²˜ë¦¬

---

## 6ë‹¨ê³„: í† í¬ë‚˜ì´ì € í•™ìŠµ

í…ìŠ¤íŠ¸ë¥¼ í† í°ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” BPE í† í¬ë‚˜ì´ì €ë¥¼ í•™ìŠµí•©ë‹ˆë‹¤.

```bash
uv run python scripts/train_tokenizer.py
```

**ê²°ê³¼**: `data/tokenizer.json` ìƒì„±

> ğŸ“š **ì°¸ê³ **: [04-tokenizer.md](docs/04-tokenizer.md) - í† í¬ë‚˜ì´ì €

---

## 7ë‹¨ê³„: ë°”ì´ë„ˆë¦¬ ë°ì´í„°ì…‹ ìƒì„±

í† í°í™”ëœ ë°ì´í„°ë¥¼ í•™ìŠµìš© ë°”ì´ë„ˆë¦¬ íŒŒì¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

```bash
uv run python scripts/build_bin_dataset.py
```

**ê²°ê³¼**: `data/train.bin`, `data/val.bin` ìƒì„±

> ğŸ“š **ì°¸ê³ **: [03-data-preparation.md](docs/03-data-preparation.md) - ë°ì´í„° ì „ì²˜ë¦¬

---

## 8ë‹¨ê³„: GPT ëª¨ë¸ í•™ìŠµ

Transformer ê¸°ë°˜ GPT ëª¨ë¸ì„ í•™ìŠµí•©ë‹ˆë‹¤.

```bash
uv run python scripts/train_gpt.py
```

**ê²°ê³¼**: `checkpoints/ckpt.pt` ìƒì„±

í•™ìŠµ ì¤‘ ë‹¤ìŒê³¼ ê°™ì€ ì¶œë ¥ì´ í‘œì‹œë©ë‹ˆë‹¤:
```
step 0: train loss 10.234, val loss 10.198
step 100: train loss 6.543, val loss 6.612
...
```

Lossê°€ ì ì  ì¤„ì–´ë“¤ë©´ í•™ìŠµì´ ì˜ ë˜ê³  ìˆëŠ” ê²ƒì…ë‹ˆë‹¤.

> ğŸ“š **ì°¸ê³ **: [05-model-architecture.md](docs/05-model-architecture.md) - ëª¨ë¸ ì•„í‚¤í…ì²˜ | [06-training.md](docs/06-training.md) - GPT í•™ìŠµ

---

## 9ë‹¨ê³„: í…ìŠ¤íŠ¸ ìƒì„±

í•™ìŠµëœ ëª¨ë¸ë¡œ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

```bash
uv run python scripts/generate.py
```

**ì˜ˆì‹œ ì¶œë ¥**:
```
[QUESTION]
ë¯¸êµ­ ì‹¤ë¦¬ì½˜ë°¸ë¦¬ ì†Œí”„íŠ¸ì›¨ì–´ ì—”ì§€ë‹ˆì–´ ì±„ìš©
[/QUESTION]

[ANSWER]
ìš”ì•½:
- ì‹¤ë¦¬ì½˜ë°¸ë¦¬ ì£¼ìš” ê¸°ì—… ì±„ìš© ì •ë³´

êµ¬ì¸ ì •ë³´:
- Google Inc.
  - í¬ì§€ì…˜: Senior Software Engineer
  - ì—°ë´‰: $150,000 - $200,000
  - ìœ„ì¹˜: Mountain View, CA
[/ANSWER]
```

> ğŸ“š **ì°¸ê³ **: [07-generation.md](docs/07-generation.md) - í…ìŠ¤íŠ¸ ìƒì„±

---

## ì „ì²´ ì‹¤í–‰ ìˆœì„œ ìš”ì•½

```bash
# 1. í”„ë¡œì íŠ¸ ì„¤ì •
uv init
uv add torch tokenizers tqdm numpy
mkdir -p data scripts checkpoints

# 2. ìˆœì°¨ ì‹¤í–‰
uv run python scripts/prepare_samples.py
uv run python scripts/train_tokenizer.py
uv run python scripts/build_bin_dataset.py
uv run python scripts/train_gpt.py
uv run python scripts/generate.py
```

